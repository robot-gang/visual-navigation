<!-- Dataset -->
<hr>
<center><h1>Name</h1></center>
<center>
  <!-- <a href="https://github.com/robot-gang/visual-navigation"><img class="round" style="width:70%" src="./img/dataset.jpg"></a> -->
  #TODO: Add an image for the dataset
</center>
<br>
#TODO: Add some description for the dataset
<!-- To address challenges of training visual navigation agents -->
<!-- around humans, in this paper we introduce the Human -->
<!-- Active Navigation Dataset (HumANav), an active dataset for -->
<!-- navigation around humans in photo-realistic environments. The dataset consists of scans -->
<!-- of 6000 synthetic but realistic humans from the <a href="https://www.di.ens.fr/willow/research/surreal/data/">SURREAL</a> -->
<!-- dataset placed in office buildings from <a href="http://buildingparser.stanford.edu/dataset.html">Stanford Large -->
<!--   Scale 3D Indoor Spaces Dataset</a>, though in principal scans -->
<!-- from any indoor office environment can be used. HumANav -->
<!-- allows for user manipulation of human agents within the -->
<!-- building and provides photorealistic renderings (RGB, Depth, -->
<!-- Surface Normals, etc.) via a standard perspective projection -->
<!-- camera. Critically, HumANav also ensures important visual -->
<!-- cues associated with human movement are present in images -->
<!-- (i.e. if a human is walking quickly its legs will be far apart), -->
<!-- facilitating reasoning about human motion. -->

<br>
<center>
  <span style="font-size:28px">&nbsp;<a href="https://github.com/robot-gang/visual-navigation">[GitHub]</a></span>
</center>



