{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast(file, nms_file, non_nms_file):\n",
    "    img = cv.imread(file,0)\n",
    "\n",
    "    # Initiate FAST object with default values\n",
    "    fast = cv.FastFeatureDetector_create()\n",
    "\n",
    "    # find and draw the keypoints\n",
    "    kp = fast.detect(img,None)\n",
    "    img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "\n",
    "    # Print all default params\n",
    "    print( \"Threshold: {}\".format(fast.getThreshold()) )\n",
    "    print( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\n",
    "    print( \"neighborhood: {}\".format(fast.getType()) )\n",
    "    print( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\n",
    "    cv.imwrite(nms_file,img2)\n",
    "\n",
    "    # Disable nonmaxSuppression\n",
    "    fast.setNonmaxSuppression(0)\n",
    "    kp = fast.detect(img,None)\n",
    "    print( \"Total Keypoints without nonmaxSuppression: {}\".format(len(kp)) )\n",
    "    img3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "    cv.imwrite(non_nms_file,img3)\n",
    "\n",
    "def display(img1, img2, title1, title2):\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (15, 7))\n",
    "    axs[0].imshow(img1)\n",
    "    axs[1].imshow(img2)\n",
    "    axs[0].set_title(title1)\n",
    "    axs[1].set_title(title2)\n",
    "    \n",
    "def display_files(file1, file2, title1='', title2=''):\n",
    "    img1 = mpimg.imread(file1)\n",
    "    img2 = mpimg.imread(file2)\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (15, 7))\n",
    "    axs[0].imshow(img1, cmap='gray')\n",
    "    axs[1].imshow(img2, cmap='gray')\n",
    "    axs[0].set_title(title1)\n",
    "    axs[1].set_title(title2)\n",
    "    \n",
    "def orb(file):\n",
    "    img = cv.imread(file,0)\n",
    "    \n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create()\n",
    "    \n",
    "    # find the keypoints with ORB\n",
    "    kp = orb.detect(img,None)\n",
    "    \n",
    "    # compute the descriptors with ORB\n",
    "    kp, des = orb.compute(img, kp)\n",
    "    \n",
    "    # draw only keypoints location,not size and orientation\n",
    "    img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "    plt.figure(figsize=(15,15)), plt.imshow(img2), plt.show()\n",
    "    \n",
    "def feature_matching_bf_orb(file1, file2):\n",
    "    img1 = cv.imread(file1,cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "    img2 = cv.imread(file2,cv.IMREAD_GRAYSCALE) # trainImage\n",
    "    \n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "    \n",
    "    # create BFMatcher object\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    # Match descriptors.\n",
    "    matches = bf.match(des1,des2)\n",
    "    \n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    # Draw first 10 matches.\n",
    "    img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(20,10)), plt.imshow(img3),plt.show()\n",
    "    \n",
    "def feature_matching_bf_sift(file1, file2):\n",
    "    img1 = cv.imread(file1,cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "    img2 = cv.imread(file2,cv.IMREAD_GRAYSCALE) # trainImage\n",
    "    \n",
    "    # Initiate SIFT detector\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    \n",
    "    # BFMatcher with default params\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1,des2,k=2)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append([m])\n",
    "            \n",
    "    # cv.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(20,10)), plt.imshow(img3),plt.show()\n",
    "    \n",
    "def feature_matching_flann_sift(file1, file2):\n",
    "    img1 = cv.imread(file1,cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "    img2 = cv.imread(file2,cv.IMREAD_GRAYSCALE) # trainImage\n",
    "    \n",
    "    # Initiate SIFT detector\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    \n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    \n",
    "#     # Need to draw only good matches, so create a mask\n",
    "#     matchesMask = [[0,0] for i in range(len(matches))]\n",
    "    \n",
    "#     # ratio test as per Lowe's paper\n",
    "#     for i,(m,n) in enumerate(matches):\n",
    "#         if m.distance < 0.7*n.distance:\n",
    "#             matchesMask[i]=[1,0]\n",
    "            \n",
    "#     draw_params = dict(matchColor = (0,255,0),\n",
    "#                        singlePointColor = (255,0,0),\n",
    "#                        matchesMask = matchesMask[:10],\n",
    "#                        flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "#     img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches[:10],None,**draw_params)\n",
    "#     plt.figure(figsize=(20,10)), plt.imshow(img3),plt.show()\n",
    "    \n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append([m])\n",
    "            \n",
    "    # cv.drawMatchesKnn expects list of lists as matches.\n",
    "    img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good[:30],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.figure(figsize=(20,10)), plt.imshow(img3),plt.show()\n",
    "    \n",
    "    \n",
    "def down_sp(file, down1_file, down2_file, down3_file):\n",
    "    src = cv.imread(file, cv.IMREAD_GRAYSCALE)\n",
    "    print('Original shape: ', src.shape)\n",
    "    \n",
    "    rows, cols = map(int, src.shape)\n",
    "    down1 = cv.pyrDown(src, dstsize=(cols // 2, rows // 2))\n",
    "    print('Down1 shape: ', down1.shape)\n",
    "    cv.imwrite(down1_file, down1)\n",
    "    \n",
    "    rows, cols = map(int, down1.shape)\n",
    "    down2 = cv.pyrDown(down1, dstsize=(cols // 2, rows // 2))\n",
    "    print('Down2 shape: ', down2.shape)\n",
    "    cv.imwrite(down2_file, down2)\n",
    "    \n",
    "    rows, cols = map(int, down2.shape)\n",
    "    down3 = cv.pyrDown(down2, dstsize=(cols // 2, rows // 2))\n",
    "    print('Down2 shape: ', down3.shape)\n",
    "    cv.imwrite(down3_file, down3)\n",
    "    \n",
    "    plt.figure(figsize=(10,10)), plt.imshow(down3), plt.show()\n",
    "    \n",
    "def detect_moving_obj(file1, file2):\n",
    "    \"\"\"\n",
    "    Extract the features of self.prev_gray and cur_gray using FAST detector and BRIEF\n",
    "    :param cur_gray: the input grayscale image\n",
    "    :return: key points and descriptors of self.prev_gray and cur_gray\n",
    "    \"\"\"\n",
    "    fast = cv.xfeatures2d.FAST_create()\n",
    "\n",
    "    # find the keypoints with FAST and descriptors of self.prev_gray\n",
    "    kp1 = fast.detect(self.prev_gray, None)\n",
    "    kp1, des1 = brief.compute(self.prev_gray, kp1[:200])\n",
    "\n",
    "    # find the keypoints with FAST and descriptors of cur_gray\n",
    "    kp2 = self.fast.detect(cur_gray, None)\n",
    "    kp2, des2 = self.brief.compute(cur_gray, kp2[:200])\n",
    "\n",
    "    return kp1, des1, kp2, des2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast('images/1.jpg', 'images/fast/1_true.png', 'images/fast/1_false.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_files('images/1_true.png', 'images/1_false.png', '1_true', '1_false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb('images/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_bf_orb('images/box1.jpg', 'images/box2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/1.jpg', 'images/1_down1.jpg', 'images/1_down2.jpg', 'images/1_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/2.jpg', 'images/2_down1.jpg', 'images/2_down2.jpg', 'images/2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/box1.jpg', 'images/box1_down1.jpg', 'images/box1_down2.jpg', 'images/box1_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/box2.jpg', 'images/box2_down1.jpg', 'images/box2_down2.jpg', 'images/box2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_bf_orb('images/box1_down3.jpg', 'images/box2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_bf_orb('images/1_down3.jpg', 'images/2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_bf_sift('images/box1_down3.jpg', 'images/box2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_bf_sift('images/1_down3.jpg', 'images/2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_flann_sift('images/1_down3.jpg', 'images/2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matching_flann_sift('images/box1_down3.jpg', 'images/box2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/ball1.jpg', 'images/ball1_down1.jpg', 'images/ball1_down2.jpg', 'images/ball1_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/ball2.jpg', 'images/ball2_down1.jpg', 'images/ball2_down2.jpg', 'images/ball2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/book1.jpg', 'images/book1_down1.jpg', 'images/book1_down2.jpg', 'images/book1_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/book2.jpg', 'images/book2_down1.jpg', 'images/book2_down2.jpg', 'images/book2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/moving_bottle1.jpg', 'images/moving_bottle1_down1.jpg', 'images/moving_bottle1_down2.jpg', 'images/moving_bottle1_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_sp('images/moving_bottle2.jpg', 'images/moving_bottle2_down1.jpg', 'images/moving_bottle2_down2.jpg', 'images/moving_bottle2_down3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
