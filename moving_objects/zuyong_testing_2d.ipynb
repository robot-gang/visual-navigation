{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import detector\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skvideo.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = 76\n",
    "num2 = 79\n",
    "\n",
    "im1 = 'imgs/{}_cam-image_array_.jpg'.format(num1)\n",
    "im2 = 'imgs/{}_cam-image_array_.jpg'.format(num2)\n",
    "depth1 = 'imgs/{}_cam-depth_array_.png'.format(num1)\n",
    "depth2 = 'imgs/{}_cam-depth_array_.png'.format(num2)\n",
    "\n",
    "im1 = cv2.imread(im1, cv2.IMREAD_GRAYSCALE)\n",
    "im2 = cv2.imread(im2, cv2.IMREAD_GRAYSCALE)\n",
    "depth1 = cv2.imread(depth1, -1)\n",
    "depth2 = cv2.imread(depth2, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect = detector.Detector(im1, im2, depth1, depth2, detector='fast')\n",
    "# detect = detector.Detector(im1, im2)\n",
    "kp1, des1, kp2, des2 = detect.feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches = detect.fMatcher.knnMatch(des2, des1, k=2)\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append(m)\n",
    "# matches = sorted(matches, key=lambda x: x.distance)[:400]\n",
    "img3 = cv2.drawMatches(detect.img1,kp1,detect.img2,kp2,good[:300],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(good)\n",
    "pts1 = np.zeros((num, 2), dtype=np.float32)\n",
    "pts2 = np.zeros((num, 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(good):\n",
    "    pts1[i, :] = kp1[match.trainIdx].pt\n",
    "    pts2[i, :] = kp2[match.queryIdx].pt\n",
    "    \n",
    "H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "size = im1.shape\n",
    "warped_im1 = cv2.warpPerspective(im1, H, (size[1], size[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 12))\n",
    "ax[0].imshow(im1, cmap='gray')\n",
    "ax[1].imshow(warped_im1, cmap='gray')\n",
    "ax[2].imshow(im2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_im1_blur = cv2.GaussianBlur(warped_im1, (5, 5), 0)\n",
    "im2_blur = cv2.GaussianBlur(im2, (5, 5), 0)\n",
    "\n",
    "normalized_im1 = (warped_im1_blur - np.mean(warped_im1_blur)) / np.std(warped_im1_blur) \n",
    "normalized_im2 = (im2_blur - np.mean(im2_blur)) / np.std(im2_blur)\n",
    "diff = (np.abs(normalized_im1 - normalized_im2) * 255).astype(np.uint8)\n",
    "if np.max(diff) - np.min(diff) >= 250:\n",
    "    result = cv2.threshold(diff,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "else:\n",
    "    result = np.zeros(im2_blur.shape)\n",
    "plt.imshow(result, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(im1, im2):\n",
    "#     detect = detector.Detector(im1, im2, depth1, depth2, detector='fast')\n",
    "    detect = detector.Detector(im1, im2)\n",
    "    kp1, des1, kp2, des2 = detect.feature_extraction()\n",
    "    \n",
    "    matches = detect.fMatcher.knnMatch(des2, des1, k=2)\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "            \n",
    "    num = len(good)\n",
    "    pts1 = np.zeros((num, 2), dtype=np.float32)\n",
    "    pts2 = np.zeros((num, 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(good):\n",
    "        pts1[i, :] = kp1[match.trainIdx].pt\n",
    "        pts2[i, :] = kp2[match.queryIdx].pt\n",
    "\n",
    "    H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "    size = im1.shape\n",
    "    warped_im1 = cv2.warpPerspective(im1, H, (size[1], size[0]))\n",
    "    \n",
    "    warped_im1_blur = cv2.GaussianBlur(warped_im1, (5, 5), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (5, 5), 0)\n",
    "\n",
    "    normalized_im1 = (warped_im1_blur - np.mean(warped_im1_blur)) / np.std(warped_im1_blur) \n",
    "    normalized_im2 = (im2_blur - np.mean(im2_blur)) / np.std(im2_blur)\n",
    "    diff = (np.abs(normalized_im1 - normalized_im2) * 255).astype(np.uint8)\n",
    "    if np.max(diff) - np.min(diff) >= 250:\n",
    "        result = cv2.threshold(diff,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    else:\n",
    "        result = np.zeros(im2_blur.shape)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = []\n",
    "# for i in range(70, 340):\n",
    "#     filename = 'imgs/{}_cam-image_array_.jpg'.format(i)\n",
    "#     img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "#     imgs.append(img)\n",
    "# io.vwrite(\"walking.MOV\", imgs) \n",
    "\n",
    "images = io.vread('videos/chicken_ds1.MOV', as_grey=True)\n",
    "print(images.shape)\n",
    "    \n",
    "video = []\n",
    "failure = 0\n",
    "for i, frame in enumerate(images):\n",
    "    frame = frame[:, :, 0]\n",
    "    if i < 3:\n",
    "        detected = np.zeros(frame.shape)\n",
    "    else:\n",
    "        try:\n",
    "            detected = detect(images[i-3], frame)\n",
    "        except:\n",
    "            failure += 1\n",
    "            detected = np.zeros(frame.shape)\n",
    "\n",
    "    img = np.vstack((frame, detected))\n",
    "    video.append(img)\n",
    "\n",
    "print(\"failure: \", failure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.vwrite('videos/chicken_ds1_detected.MOV', video)\n",
    "# io.vwrite('videos/walking_detected_short.MOV', video[:71])\n",
    "# io.vwrite('videos/walking_detected_median.MOV', video[:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(video[6], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
