{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import detector\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skvideo.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = 108\n",
    "num2 = 111\n",
    "\n",
    "im1 = 'imgs/{}_cam-image_array_.jpg'.format(num1)\n",
    "im2 = 'imgs/{}_cam-image_array_.jpg'.format(num2)\n",
    "depth1 = 'imgs/{}_cam-depth_array_.png'.format(num1)\n",
    "depth2 = 'imgs/{}_cam-depth_array_.png'.format(num2)\n",
    "\n",
    "im1 = cv2.imread(im1, cv2.IMREAD_GRAYSCALE)\n",
    "im2 = cv2.imread(im2, cv2.IMREAD_GRAYSCALE)\n",
    "depth1 = cv2.imread(depth1, -1)\n",
    "depth2 = cv2.imread(depth2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect = detector.Detector(im1, im2, depth1, depth2, detector='fast')\n",
    "kp1, des1, kp2, des2 = detect.feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches = detect.fMatcher.knnMatch(des2, des1, k=2)\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append(m)\n",
    "img3 = cv2.drawMatches(detect.img1,kp1,detect.img2,kp2,good[:300],None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.imshow(img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(good)\n",
    "pts1 = np.zeros((num, 2), dtype=np.float32)\n",
    "pts2 = np.zeros((num, 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(good):\n",
    "    pts1[i, :] = kp1[match.trainIdx].pt\n",
    "    pts2[i, :] = kp2[match.queryIdx].pt\n",
    "    \n",
    "H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "size = im1.shape\n",
    "warped_im1 = cv2.warpPerspective(im1, H, (size[1], size[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 12))\n",
    "ax[0].imshow(im1, cmap='gray')\n",
    "ax[1].imshow(warped_im1, cmap='gray')\n",
    "ax[2].imshow(im2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_im1_blur = cv2.GaussianBlur(warped_im1, (5, 5), 0)\n",
    "im2_blur = cv2.GaussianBlur(im2, (5, 5), 0)\n",
    "\n",
    "normalized_im1 = (warped_im1_blur - np.mean(warped_im1_blur)) / np.std(warped_im1_blur) \n",
    "normalized_im2 = (im2_blur - np.mean(im2_blur)) / np.std(im2_blur)\n",
    "diff = (np.abs(normalized_im1 - normalized_im2) * 255).astype(np.uint8)\n",
    "if np.max(diff) - np.min(diff) >= 250:\n",
    "    result = cv2.threshold(diff,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "else:\n",
    "    result = np.zeros(im2_blur.shape)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
