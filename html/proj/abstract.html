<!-- Abstract -->
<hr>
<center><h1>Overview</h1></center>
<p>
We extend recently proposed solutions for tackling autonomous navigation
in unknown environments, and demonstrate a method for identifying
dynamic obstacles only using information from an RGB-D camera.  we
successfully extended the HumANav dataset to allow for a wider range of
scenarios that can be used to train our perception module. We designed
an algorithm that successfully and accurately detects the moving objects
by combining changes in intensity and depth. The result of data
generation and moving object detection look appealing and
encouraging. The end goal is to design and train a neural network for
waypoint detection and integrating all modules of our design and
applying to hardwares.  This would solve the autonomous navigation in
dynamic unknown environments with low cost sensors. Especially, it would
work for indoor robots which operate at a low speed and the environments
are most likely to be dynamic. Warehouse robots would benefit the most.
</p>
<center>
  <span style="font-size:28px">&nbsp;<a href="./resources/finalproj_paper.pdf" target="_blank">[Our Paper!]</a>
</center>
<br><br>
